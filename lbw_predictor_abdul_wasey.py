# -*- coding: utf-8 -*-
"""Lbw_predictor_Abdul Wasey.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q4kvLHNDsJcEBuq8q91ttcEhmzi5A6in
"""

from google.colab.patches import cv2_imshow

import cv2
import numpy as np
import tensorflow as tf
from google.colab.patches import cv2_imshow

IMG_SIZE = 224

base_model = tf.keras.applications.MobileNetV2(
    weights="imagenet",
    include_top=False,
    input_shape=(IMG_SIZE, IMG_SIZE, 3)
)

model = tf.keras.Sequential([
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(128, activation="relu"),
    tf.keras.layers.Dense(1, activation="sigmoid")  # OUT / NOT OUT
])
model.compile(optimizer="adam", loss="binary_crossentropy")

from google.colab import files
uploaded = files.upload()
video_path = list(uploaded.keys())[0]

cap = cv2.VideoCapture(video_path)
frame_count = 0
MAX_FRAMES = 100

ball_positions = []
last_frame = None

kalman = cv2.KalmanFilter(4,2)
kalman.measurementMatrix = np.array([[1,0,0,0],[0,1,0,0]],np.float32)
kalman.transitionMatrix = np.array([[1,0,1,0],[0,1,0,1],[0,0,1,0],[0,0,0,1]],np.float32)
kalman.processNoiseCov = np.eye(4, dtype=np.float32)*0.03


while cap.isOpened() and frame_count < MAX_FRAMES:
    ret, frame = cap.read()
    if not ret or frame is None:
        break

    last_frame = frame.copy()
    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(frame_gray, (5,5), 0)

    circles = cv2.HoughCircles(
        blur, cv2.HOUGH_GRADIENT, dp=1.2, minDist=15,
        param1=50, param2=30, minRadius=5, maxRadius=25
    )
    if circles is not None:
        circles = np.uint16(np.around(circles))
        x, y = circles[0,0][0], circles[0,0][1]
        measurement = np.array([[np.float32(x)], [np.float32(y)]])
        kalman.correct(measurement)
        prediction = kalman.predict()
        pred_x, pred_y = int(prediction[0]), int(prediction[1])
        ball_positions.append((pred_x, pred_y))
        # draw ball and predicted
        cv2.circle(frame, (x,y), circles[0,0][2], (0,0,255), 2)
        cv2.circle(frame, (pred_x, pred_y), 3, (0,255,255), -1)

    frame_count += 1

cap.release()

frame = last_frame
ball_positions = np.array(ball_positions)
if len(ball_positions) >= 2:
    x = ball_positions[:,0]
    y = ball_positions[:,1]

    coef = np.polyfit(x, y, 2)
    poly = np.poly1d(coef)


    for xi in range(min(x), max(x), 3):
        yi = int(poly(xi))
        cv2.circle(frame, (xi, yi), 2, (255,0,0), -1)


    pitching_point = (x[0], y[0])
    impact_point = (x[-1], y[-1])

    cv2.circle(frame, pitching_point, 5, (0,255,0), -1)
    cv2.putText(frame, "Pitching", (pitching_point[0]+5, pitching_point[1]-5),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1)

    cv2.circle(frame, impact_point, 5, (0,0,255), -1)
    cv2.putText(frame, "Impact", (impact_point[0]+5, impact_point[1]-5),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1)

cnn_input = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))
cnn_input = cv2.cvtColor(cnn_input, cv2.COLOR_BGR2RGB)
cnn_input = cnn_input / 255.0
cnn_input = np.expand_dims(cnn_input, axis=0)

cnn_pred = model.predict(cnn_input)[0][0]

frame_width = frame.shape[1]
stump_x = frame_width - 50
trajectory_hits_stump = False
if len(ball_positions) >= 2:
    trajectory_hits_stump = poly(stump_x) < frame.shape[0] - 50

if cnn_pred > 0.5 and trajectory_hits_stump:
    decision = "üèè Decision: OUT (LBW)"
else:
    decision = "üèè Decision: NOT OUT"

cv2.putText(frame, decision, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)

cv2_imshow(frame)

